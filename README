# BEGIN_ICS_COPYRIGHT8 ****************************************
#
# Copyright (c) 2021, Cornelis Networks
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#     * Redistributions of source code must retain the above copyright notice,
#       this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright
#       notice, this list of conditions and the following disclaimer in the
#       documentation and/or other materials provided with the distribution.
#     * Neither the name of Cornelis Networks nor the names of its contributors
#       may be used to endorse or promote products derived from this software
#       without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# END_ICS_COPYRIGHT8   ****************************************

#[ICS VERSION STRING: unknown]

README contents:
- DEPENDENCIES
- BUILDING
- RUNNING
- NCCL ranks, PSM2 endpoints, and hfi1 num_user_contexts

DEPENDENCIES
============

libpsm2 w/NCCL support (https://github.com/cornelisnetworks/opa-psm2/tree/PSM2_11.2.NCCL) installed on GPU nodes
hfi1-gpudirect
NCCL 2.8.3 must be installed on GPU nodes
NCCL development clone to build psm2-nccl plugin; available here - https://github.com/NVIDIA/nccl.git
* Must also build NCCL development clone in order to generate headers needed to build PSM2-NCCL.

BUILDING
========
cd into psm2-nccl clone and do "make".

Set 'BUILDDIR' make variable to control where libnccl-net.so goes. By default, BUILDDIR is '.'.

See Makefile for other directory and build variables.

RUNNING
=======
Add directory containing psm2-nccl libnccl-net.so to LD_LIBRARY_PATH and ensure LD_LIBRARY_PATH is exported to rank environments.

Run your NCCL app using OpenMPI mpirun, e.g.:
	mpirun -np 2 --map-by ppr:1:node -host <host1>,<host2> -x PSM2_CUDA=1 -x PSM2_GPUDIRECT=1 -x PSM2_GDRCOPY=0 -x PSM2_MULTI_EP=1 -x LD_LIBRARY_PATH -x NCCL_NET_GDR_LEVEL=5 build/all_reduce_perf

Environment variable notes:
* PSM2_MULTI_EP=1 must be set in all ranks' environments. Not doing so may cause the job to fail on a psm2_ep_open() with the error 'PSM2_TOO_MANY_ENDPOINTS'.
* PSM2_CUDA=1, PSM2_GPUDIRECT must be set in all ranks' environments for PSM2-NCCL to use GPUDirect.
* PSM2_RCVTHREAD=0 is not supported with PSM2-NCCL.
* PSM2-NCCL uses NCCL's logging system for debug output. All PSM2-NCCL output is logged under the NCCL 'NET' logging subsystem. To get PSM2-NCCL debug output, add '-x NCCL_DEBUG=INFO -x NCCL_DEBUG_SUBSYS=NET -x PSM2_NCCL_LOG_LEVEL=2' to your mpirun line. See src/include/psm2_nccl_debug.h for PSM2-NCCL log levels.

PSM2-NCCL only supports OpenMPI at present. You may use CUDA-aware or CUDA-naive OpenMPI but per this (https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/mpi.html#inter-gpu-communication-with-cuda-aware-mpi), using NCCL and CUDA-aware MPI operations concurrently may cause deadlocks.

PSM2 does not support more than one GPU per host process and so PSM2-NCCL similarly does not support more than one GPU per host process.

NCCL ranks, PSM2 endpoints, and hfi1 num_user_contexts
======================================================
PSM2-NCCL uses one PSM2 endpoint for each NCCL communicator object. Each NCCL rank requires one send and one receive NCCL communicator object to establish bidirectional communications with a remote NCCL rank. As NCCL typically requires an all-to-all communication pattern, the size of a NCCL job with PSM2-NCCL is limited to (number of PSM2 endpoints)/2.

The number of PSM2 endpoints is limited by the number of hfi1 contexts. Typically, hfi1 will  have as many contexts as there are physical CPU cores on the system. The number of hfi1 contexts can be increased up to a limit of 160 using the 'num_user_contexts' kernel module parameter.
